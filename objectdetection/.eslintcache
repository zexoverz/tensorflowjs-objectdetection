[{"C:\\Programming\\Learning\\tensorflowjs-objectdetection\\objectdetection\\src\\reportWebVitals.js":"1","C:\\Programming\\Learning\\tensorflowjs-objectdetection\\objectdetection\\src\\App.js":"2","C:\\Programming\\Learning\\tensorflowjs-objectdetection\\objectdetection\\src\\index.js":"3"},{"size":362,"mtime":1606214356961,"results":"4","hashOfConfig":"5"},{"size":3555,"mtime":1606219173432,"results":"6","hashOfConfig":"5"},{"size":500,"mtime":1606214356961,"results":"7","hashOfConfig":"5"},{"filePath":"8","messages":"9","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"kn50ly",{"filePath":"10","messages":"11","errorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"12"},{"filePath":"13","messages":"14","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"C:\\Programming\\Learning\\tensorflowjs-objectdetection\\objectdetection\\src\\reportWebVitals.js",[],"C:\\Programming\\Learning\\tensorflowjs-objectdetection\\objectdetection\\src\\App.js",["15","16"],"import './App.css';\nimport React, {useEffect} from 'react';\nimport * as tf from '@tensorflow/tfjs';\nconst cocoSsd = require('@tensorflow-models/coco-ssd');\n\nfunction App() {\n\n  const videoRef = React.createRef();\n  const canvasRef = React.createRef();\n\n  let styles = {\n    position: 'fixed',\n    left: 150,\n  };\n\n  const detectFromVideoFrame = (model, video) => {\n    model.detect(video).then(predictions => {\n      showDetections(predictions);\n\n      requestAnimationFrame(() => {\n        detectFromVideoFrame(model, video);\n      });\n    }, (error) => {\n      console.log(\"Couldn't start the webcam\")\n      console.error(error)\n    })\n  }\n\n  const showDetections = predictions => {\n    const ctx = canvasRef.current.getContext(\"2d\");\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n    const font = \"24px helvetica\";\n    ctx.font = font;\n    ctx.textBaseline = \"top\";\n\n    predictions.forEach(prediction => {\n      const x = prediction.bbox[0];\n      const y = prediction.bbox[1];\n      const width = prediction.bbox[2];\n      const height = prediction.bbox[3];\n      // Draw the bounding box.\n      ctx.strokeStyle = \"#2fff00\";\n      ctx.lineWidth = 1;\n      ctx.strokeRect(x, y, width, height);\n      // Draw the label background.\n      ctx.fillStyle = \"#2fff00\";\n      const textWidth = ctx.measureText(prediction.class).width;\n      const textHeight = parseInt(font, 10);\n      // draw top left rectangle\n      ctx.fillRect(x, y, textWidth + 10, textHeight + 10);\n      // draw bottom left rectangle\n      ctx.fillRect(x, y + height - textHeight, textWidth + 15, textHeight + 10);\n\n      // Draw the text last to ensure it's on top.\n      ctx.fillStyle = \"#000000\";\n      ctx.fillText(prediction.class, x, y);\n      ctx.fillText(prediction.score.toFixed(2), x, y + height - textHeight);\n    });\n  };\n\n  useEffect(() => {\n    if (navigator.mediaDevices.getUserMedia) {\n      // define a Promise that'll be used to load the webcam and read its frames\n      const webcamPromise = navigator.mediaDevices\n        .getUserMedia({\n          video: true,\n          audio: false,\n        })\n        .then(stream => {\n          // pass the current frame to the window.stream\n          window.stream = stream;\n          // pass the stream to the videoRef\n          videoRef.current.srcObject = stream;\n\n          return new Promise(resolve => {\n            videoRef.current.onloadedmetadata = () => {\n              resolve();\n            };\n          });\n        }, (error) => {\n          console.log(\"Couldn't start the webcam\")\n          console.error(error)\n        });\n\n      // define a Promise that'll be used to load the model\n      const loadlModelPromise = cocoSsd.load();\n      \n      // resolve all the Promises\n      Promise.all([loadlModelPromise, webcamPromise])\n        .then(values => {\n          detectFromVideoFrame(values[0], videoRef.current);\n        })\n        .catch(error => {\n          console.error(error);\n        });\n    }\n  }, [videoRef])\n  \n  return (\n    <div className=\"App\" style={{ display: 'flex', justifyContent: \"center\", alignItems: \"center\"}}>\n      {/* <h1 className=\"App-header\">Demo of TensorFlow.js Coco SSD's model object detection</h1> */}\n      <div style={{left: 50}}>\n        <video\n            style={styles}\n            autoPlay\n            muted\n            ref={videoRef}\n            width=\"720\"\n            height=\"600\"\n            className = \"video\"\n          />\n        <canvas style={styles} ref={canvasRef} width=\"720\" height=\"600\" />\n      </div>\n    </div>\n  );\n}\n\nexport default App;\n","C:\\Programming\\Learning\\tensorflowjs-objectdetection\\objectdetection\\src\\index.js",[],{"ruleId":"17","severity":1,"message":"18","line":3,"column":13,"nodeType":"19","messageId":"20","endLine":3,"endColumn":15},{"ruleId":"21","severity":1,"message":"22","line":97,"column":6,"nodeType":"23","endLine":97,"endColumn":16,"suggestions":"24"},"no-unused-vars","'tf' is defined but never used.","Identifier","unusedVar","react-hooks/exhaustive-deps","React Hook useEffect has a missing dependency: 'detectFromVideoFrame'. Either include it or remove the dependency array.","ArrayExpression",["25"],{"desc":"26","fix":"27"},"Update the dependencies array to be: [detectFromVideoFrame, videoRef]",{"range":"28","text":"29"},[2966,2976],"[detectFromVideoFrame, videoRef]"]